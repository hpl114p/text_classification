{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyM7+ko/OrCTfPzpIKMplO0Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Transformer Architecture**\n"],"metadata":{"id":"WVz_zi-UYB-i"}},{"cell_type":"code","source":["!pip install torchtext==0.17.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzlbeGx4YOce","executionInfo":{"status":"ok","timestamp":1763191308088,"user_tz":-420,"elapsed":179826,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}},"outputId":"4880591e-b95a-4015-ea58-3741a38c780e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchtext==0.17.2\n","  Downloading torchtext-0.17.2-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.17.2) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.17.2) (2.32.4)\n","Collecting torch==2.2.2 (from torchtext==0.17.2)\n","  Downloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.17.2) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchtext==0.17.2) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchtext==0.17.2) (4.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchtext==0.17.2) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchtext==0.17.2) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchtext==0.17.2) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchtext==0.17.2) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->torchtext==0.17.2)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->torchtext==0.17.2)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->torchtext==0.17.2)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->torchtext==0.17.2)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->torchtext==0.17.2)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->torchtext==0.17.2)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->torchtext==0.17.2)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->torchtext==0.17.2)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->torchtext==0.17.2)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->torchtext==0.17.2)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->torchtext==0.17.2)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchtext==0.17.2) (12.6.85)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.17.2) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.17.2) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.17.2) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.17.2) (2025.10.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.2->torchtext==0.17.2) (3.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.2->torchtext==0.17.2) (1.3.0)\n","Downloading torchtext-0.17.2-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m817.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchtext\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.6.77\n","    Uninstalling nvidia-nvtx-cu12-12.6.77:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.27.3\n","    Uninstalling nvidia-nccl-cu12-2.27.3:\n","      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n","    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.8.0+cu126\n","    Uninstalling torch-2.8.0+cu126:\n","      Successfully uninstalled torch-2.8.0+cu126\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.2.2 which is incompatible.\n","torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchtext-0.17.2\n"]}]},{"cell_type":"code","source":["import torchtext\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bGeWn73pYjW2","executionInfo":{"status":"ok","timestamp":1763191313908,"user_tz":-420,"elapsed":5807,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}},"outputId":"34b4bffa-087e-4e40-9fff-52dde039468f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","A module that was compiled using NumPy 1.x cannot be run in\n","NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n","versions of NumPy, modules must be compiled with NumPy 2.0.\n","Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n","\n","If you are a user of the module, the easiest solution will be to\n","downgrade to 'numpy<2' or try to upgrade the affected module.\n","We expect that some modules will need time to support NumPy 2.\n","\n","Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n","  File \"<frozen runpy>\", line 88, in _run_code\n","  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n","    ColabKernelApp.launch_instance()\n","  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n","    await self.process_one()\n","  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n","    await dispatch(*args)\n","  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n","    await result\n","  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n","    reply_content = await reply_content\n","  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n","    res = shell.run_cell(\n","  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n","    return super().run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"/tmp/ipython-input-3900205259.py\", line 1, in <cell line: 0>\n","    import torchtext\n","  File \"/usr/local/lib/python3.12/dist-packages/torchtext/__init__.py\", line 3, in <module>\n","    from torch.hub import _get_torch_home\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/__init__.py\", line 1477, in <module>\n","    from .functional import *  # noqa: F403\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/functional.py\", line 9, in <module>\n","    import torch.nn.functional as F\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n","    from .modules import *  # noqa: F403\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n","    from .transformer import TransformerEncoder, TransformerDecoder, \\\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n","    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n","  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"]}]},{"cell_type":"markdown","source":["##**Transformer-Encoder**"],"metadata":{"id":"d6Xd9HwiYJGJ"}},{"cell_type":"markdown","source":["###**Token and Positional Embedding**"],"metadata":{"id":"z7EqVFUNYrEP"}},{"cell_type":"markdown","source":["**Token Embedding:** Represents the input tokens (usually split by subword-based tokenization) as dense vectors.\n","\n","**Positional Encoding:** Represents the position (order) of tokens in a sentence. This is typically computed using sinusoidal functions or learned during model training."],"metadata":{"id":"XRUwTlsRbtZm"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"NfQfdRUzX39y","executionInfo":{"status":"ok","timestamp":1763192514743,"user_tz":-420,"elapsed":6,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"outputs":[],"source":["class TokenAndPositionEmbedding(nn.Module):\n","  def __init__(self, vocab_size, embed_dim, max_length, device='cpu'):\n","    super().__init__()\n","    self.device = device\n","    #Token embedding\n","    self.word_emb = nn.Embedding(\n","      num_embeddings=vocab_size,\n","      embedding_dim=embed_dim\n","    )\n","    #Positional embedding\n","    self.pos_emb = nn.Embedding(\n","      num_embeddings=max_length,\n","      embedding_dim=embed_dim\n","    )\n","\n","  def forward(self, x):\n","    N, seq_len = x.size()\n","    positions = torch.arange(0, seq_len).expand(N, seq_len).to(self.device)\n","    output1 = self.word_emb(x)\n","    output2 = self.pos_emb(positions)\n","    output = output1 + output2\n","    return output"]},{"cell_type":"markdown","source":["###**Transformer-Encoder Block**"],"metadata":{"id":"poIabWSJZ19V"}},{"cell_type":"markdown","source":["**Encoder blocks:** Encode the input tokens into contextual embeddings. They include: Multi-Head Attention, Add & Normalization, Feed Forward Network\n","\n"],"metadata":{"id":"3iafSof9cDBM"}},{"cell_type":"code","source":["class TransformerEncoderBlock(nn.Module):\n","  def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n","    super().__init__()\n","    #Multi-head Attention\n","    self.attn = nn.MultiheadAttention(\n","      embed_dim=embed_dim,\n","      num_heads=num_heads,\n","      batch_first=True\n","    )\n","    #Feed Forward Network\n","    self.ffn = nn.Sequential(\n","      nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n","      nn.ReLU(),\n","      nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True)\n","    )\n","    #Add & Normalization\n","    self.layernorm_1 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n","    self.layernorm_2 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n","    self.dropout_1 = nn.Dropout(p=dropout)\n","    self.dropout_2 = nn.Dropout(p=dropout)\n","\n","  def forward(self, query, key, value):\n","    attn_output, _ = self.attn(query, key, value)\n","    attn_output = self.dropout_1(attn_output)\n","    out_1 = self.layernorm_1(query + attn_output)\n","    ffn_output = self.ffn(out_1)\n","    ffn_output = self.dropout_2(ffn_output)\n","    out_2 = self.layernorm_2(out_1 + ffn_output)\n","    return out_2"],"metadata":{"id":"zf1lrM_QX4W-","executionInfo":{"status":"ok","timestamp":1763192516682,"user_tz":-420,"elapsed":19,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["###**Transformer-Encoder**"],"metadata":{"id":"vBTsAkQhcXgD"}},{"cell_type":"code","source":["class TransformerEncoder(nn.Module):\n","  def __init__(self,\n","              src_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim,\n","              dropout=0.1, device='cpu'\n","  ):\n","    super().__init__()\n","    # Input embedding\n","    self.embedding = TokenAndPositionEmbedding(\n","      src_vocab_size, embed_dim, max_length, device\n","    )\n","    # Encoder block\n","    self.layers = nn.ModuleList(\n","      [\n","        TransformerEncoderBlock(\n","          embed_dim, num_heads, ff_dim, dropout\n","        ) for i in range(num_layers)\n","      ]\n","    )\n","\n","  def forward(self, x):\n","    output = self.embedding(x)\n","    for layer in self.layers:\n","      output = layer(output, output, output)\n","    return output"],"metadata":{"id":"0P8Az7KvX4Z2","executionInfo":{"status":"ok","timestamp":1763192518743,"user_tz":-420,"elapsed":3,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","src_vocab_size = 1000\n","embed_dim = 200\n","max_length = 100\n","num_layers = 2\n","num_heads = 4\n","ff_dim = 256"],"metadata":{"id":"uAnCmW5XX4c1","executionInfo":{"status":"ok","timestamp":1763192520701,"user_tz":-420,"elapsed":4,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["input = torch.randint(\n","  high=2,\n","  size=(batch_size, max_length),\n","  dtype=torch.int64\n",")"],"metadata":{"id":"W19s57LDX4fm","executionInfo":{"status":"ok","timestamp":1763192522229,"user_tz":-420,"elapsed":5,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["encoder = TransformerEncoder(\n","  src_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim\n",")\n","print(encoder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E-miAWLYX4iF","executionInfo":{"status":"ok","timestamp":1763193280701,"user_tz":-420,"elapsed":42,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}},"outputId":"1a3398a4-a0f4-4ddb-f72c-ea71b6259895"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["TransformerEncoder(\n","  (embedding): TokenAndPositionEmbedding(\n","    (word_emb): Embedding(1000, 200)\n","    (pos_emb): Embedding(100, 200)\n","  )\n","  (layers): ModuleList(\n","    (0-1): 2 x TransformerEncoderBlock(\n","      (attn): MultiheadAttention(\n","        (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n","      )\n","      (ffn): Sequential(\n","        (0): Linear(in_features=200, out_features=256, bias=True)\n","        (1): ReLU()\n","        (2): Linear(in_features=256, out_features=200, bias=True)\n","      )\n","      (layernorm_1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)\n","      (layernorm_2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)\n","      (dropout_1): Dropout(p=0.1, inplace=False)\n","      (dropout_2): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n",")\n"]}]},{"cell_type":"code","source":["encoded = encoder(input)"],"metadata":{"id":"iMUS96PhX4k2","executionInfo":{"status":"ok","timestamp":1763192523644,"user_tz":-420,"elapsed":452,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["encoded.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9rnLUkFwX4nn","executionInfo":{"status":"ok","timestamp":1763192523749,"user_tz":-420,"elapsed":16,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}},"outputId":"4d02dfe9-7a88-42f3-b936-3b5e00dcaeef"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 100, 200])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["##**Transformer-Decoder**"],"metadata":{"id":"NqbGjdikeV0K"}},{"cell_type":"markdown","source":["###**Transformer-Decoder Block**"],"metadata":{"id":"3if96uBged_c"}},{"cell_type":"markdown","source":["**Decoder blocks:** Take as input the historical tokens and the encoded states from the encoder, decoding to predict the next token. They include: Masked Multi-Head Attention (based on the decoder's historical tokens), Multi-Head Attention (based on the encoder outputs and current decoder state), Add & Normalization, Feed Forward Network"],"metadata":{"id":"MiaalHkifaTk"}},{"cell_type":"code","source":["class TransformerDecoderBlock(nn.Module):\n","  def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n","    super().__init__()\n","    # Masked Multi-Head Attention\n","    self.attn = nn.MultiheadAttention(\n","      embed_dim=embed_dim,\n","      num_heads=num_heads,\n","      batch_first=True\n","    )\n","    # Multi-Head Attention\n","    self.cross_attn = nn.MultiheadAttention(\n","      embed_dim=embed_dim,\n","      num_heads=num_heads,\n","      batch_first=True\n","    )\n","    # Feed Forward Network\n","    self.ffn = nn.Sequential(\n","      nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n","      nn.ReLU(),\n","      nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True)\n","    )\n","    # Add & Normalization\n","    self.layernorm_1 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n","    self.layernorm_2 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n","    self.layernorm_3 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n","    self.dropout_1 = nn.Dropout(p=dropout)\n","    self.dropout_2 = nn.Dropout(p=dropout)\n","    self.dropout_3 = nn.Dropout(p=dropout)\n","\n","  def forward(self, x, enc_output, src_mask, tgt_mask):\n","    attn_output, _ = self.attn(x, x, x, attn_mask=tgt_mask)\n","    attn_output = self.dropout_1(attn_output)\n","    out_1 = self.layernorm_1(x + attn_output)\n","\n","    attn_output, _ = self.cross_attn(\n","      out_1, enc_output, enc_output, attn_mask=src_mask\n","    )\n","    attn_output = self.dropout_2(attn_output)\n","    out_2 = self.layernorm_2(out_1 + attn_output)\n","\n","    ffn_output = self.ffn(out_2)\n","    ffn_output = self.dropout_2(ffn_output)\n","    out_3 = self.layernorm_2(out_2 + ffn_output)\n","    return out_3"],"metadata":{"id":"uwfnpv1MX4qf","executionInfo":{"status":"ok","timestamp":1763193498975,"user_tz":-420,"elapsed":42,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["###**Transformer-Decoder**"],"metadata":{"id":"nZCKigmOf6sS"}},{"cell_type":"code","source":["class TransformerDecoder(nn.Module):\n","  def __init__(self,\n","      tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim,\n","      dropout=0.1, device='cpu'\n","  ):\n","    super().__init__()\n","    # Input embedding\n","    self.embedding = TokenAndPositionEmbedding(\n","      tgt_vocab_size, embed_dim, max_length, device\n","    )\n","    # Decoder block\n","    self.layers = nn.ModuleList(\n","      [\n","        TransformerDecoderBlock(\n","          embed_dim, num_heads, ff_dim, dropout\n","        ) for i in range(num_layers)\n","      ]\n","    )\n","\n","  def forward(self, x, enc_output, src_mask, tgt_mask):\n","    output = self.embedding(x)\n","    for layer in self.layers:\n","      output = layer(output, enc_output, src_mask, tgt_mask)\n","    return output"],"metadata":{"id":"8TXP6yJxdtrk","executionInfo":{"status":"ok","timestamp":1763193500780,"user_tz":-420,"elapsed":8,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["##**Transformer**"],"metadata":{"id":"yGplL1dAheNZ"}},{"cell_type":"code","source":["class Transformer(nn.Module):\n","  def __init__(self,\n","      src_vocab_size, tgt_vocab_size,\n","      embed_dim, max_length, num_layers, num_heads, ff_dim,\n","      dropout=0.1, device='cpu'\n","  ):\n","    super().__init__()\n","    self.device = device\n","    self.encoder = TransformerEncoder(\n","      src_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim\n","    )\n","    self.decoder = TransformerDecoder(\n","      tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim\n","    )\n","    self.fc = nn.Linear(embed_dim, tgt_vocab_size)\n","\n","  def generate_mask(self, src, tgt):\n","    src_seq_len = src.shape[1]\n","    tgt_seq_len = tgt.shape[1]\n","\n","    src_mask = torch.zeros(\n","      (src_seq_len, src_seq_len),\n","      device=self.device\n","    ).type(torch.bool)\n","\n","    tgt_mask = (torch.triu(torch.ones(\n","      (tgt_seq_len, tgt_seq_len),\n","      device=self.device)\n","    ) == 1).transpose(0, 1)\n","    tgt_mask = tgt_mask.float().masked_fill(\n","      tgt_mask == 0, float('-inf')\n","    ).masked_fill(tgt_mask == 1, float(0.0))\n","    return src_mask, tgt_mask\n","\n","  def forward(self, src, tgt):\n","    src_mask, tgt_mask = self.generate_mask(src, tgt)\n","    enc_output = self.encoder(src)\n","    dec_output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n","    output = self.fc(dec_output)\n","    return output"],"metadata":{"id":"lmBdoG86dtvj","executionInfo":{"status":"ok","timestamp":1763194380593,"user_tz":-420,"elapsed":10,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["batch_size = 128\n","src_vocab_size = 1000\n","tgt_vocab_size = 2000\n","embed_dim = 200\n","max_length = 100\n","num_layers = 2\n","num_heads = 4\n","ff_dim = 256"],"metadata":{"id":"56PeKBWNdtyU","executionInfo":{"status":"ok","timestamp":1763194422808,"user_tz":-420,"elapsed":4,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["model = Transformer(\n","  src_vocab_size, tgt_vocab_size,\n","  embed_dim, max_length, num_layers, num_heads, ff_dim\n",")\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I_jydrmIdt1L","executionInfo":{"status":"ok","timestamp":1763194423687,"user_tz":-420,"elapsed":74,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}},"outputId":"5f7c9245-339b-48b1-a8b6-44adae4b8361"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Transformer(\n","  (encoder): TransformerEncoder(\n","    (embedding): TokenAndPositionEmbedding(\n","      (word_emb): Embedding(1000, 200)\n","      (pos_emb): Embedding(100, 200)\n","    )\n","    (layers): ModuleList(\n","      (0-1): 2 x TransformerEncoderBlock(\n","        (attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n","        )\n","        (ffn): Sequential(\n","          (0): Linear(in_features=200, out_features=256, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=256, out_features=200, bias=True)\n","        )\n","        (layernorm_1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)\n","        (layernorm_2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (decoder): TransformerDecoder(\n","    (embedding): TokenAndPositionEmbedding(\n","      (word_emb): Embedding(2000, 200)\n","      (pos_emb): Embedding(100, 200)\n","    )\n","    (layers): ModuleList(\n","      (0-1): 2 x TransformerDecoderBlock(\n","        (attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n","        )\n","        (cross_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n","        )\n","        (ffn): Sequential(\n","          (0): Linear(in_features=200, out_features=256, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=256, out_features=200, bias=True)\n","        )\n","        (layernorm_1): LayerNorm((200,), eps=1e-06, elementwise_affine=True)\n","        (layernorm_2): LayerNorm((200,), eps=1e-06, elementwise_affine=True)\n","        (layernorm_3): LayerNorm((200,), eps=1e-06, elementwise_affine=True)\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (fc): Linear(in_features=200, out_features=2000, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["src = torch.randint(\n","  high=2,\n","  size=(batch_size, max_length),\n","  dtype=torch.int64\n",")"],"metadata":{"id":"dstlwAE8dt3k","executionInfo":{"status":"ok","timestamp":1763194430673,"user_tz":-420,"elapsed":41,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["tgt = torch.randint(\n","  high=2,\n","  size=(batch_size, max_length),\n","  dtype=torch.int64\n",")"],"metadata":{"id":"hGJMvyN9k3BC","executionInfo":{"status":"ok","timestamp":1763194431165,"user_tz":-420,"elapsed":5,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["prediction = model(src, tgt)"],"metadata":{"id":"yugImsAVk3Do","executionInfo":{"status":"ok","timestamp":1763194438151,"user_tz":-420,"elapsed":5635,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["prediction.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICR8zuyek3F-","executionInfo":{"status":"ok","timestamp":1763194438179,"user_tz":-420,"elapsed":24,"user":{"displayName":"Phuc Hoang","userId":"11058614837244935757"}},"outputId":"9968e290-6d27-4749-f7c4-338aa4523d3d"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([128, 100, 2000])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":[],"metadata":{"id":"NpUiVJAEk3I2"},"execution_count":null,"outputs":[]}]}